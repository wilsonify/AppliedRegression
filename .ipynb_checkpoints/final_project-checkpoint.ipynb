{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, os, sys, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from matplotlib import pyplot as plt\n",
    "from fractions import Fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_column_names(self):\n",
    "    new_column_names = {old:re.sub( string=old.lower()\n",
    "                                   ,pattern='\\W' #\\W matches non-alphnumeric\n",
    "                                   ,repl='_')\\\n",
    "                              .strip('_')\n",
    "                        for old in self.columns\n",
    "                       }\n",
    "    return (self.rename(columns=new_column_names))\n",
    "pd.DataFrame.clean_column_names = clean_column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_date_columns(self):\n",
    "    for date_column in self.filter(regex=(\"date\")).columns:\n",
    "        self[date_column] = pd.to_datetime(self[date_column])\n",
    "    return self\n",
    "pd.DataFrame.parse_date_columns = parse_date_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_to_null(self,subset):\n",
    "    for column in subset:\n",
    "        self[column] = self[column].apply(lambda x: x if x != 0 else np.nan)\n",
    "    return self\n",
    "pd.DataFrame.zero_to_null = zero_to_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_multi(self, df, on):\n",
    "    return self.reset_index().merge(df.reset_index(),on=on,how='left').set_index(self.index.names)\n",
    "\n",
    "pd.DataFrame.merge_multi = merge_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deduplicate(self,key,NUMERIC='max',NON_NUMERIC='first',override={}):\n",
    "    how_to_agg = {index: NUMERIC if np.issubdtype(value,np.number) else NON_NUMERIC \n",
    "                  for (index, value) in self.dtypes.iteritems()\n",
    "                 }\n",
    "    how_to_agg.update(override)\n",
    "    return self.groupby(key).agg(how_to_agg)\n",
    "pd.DataFrame.deduplicate = deduplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_api_columns(self):\n",
    "    for api_column in self.filter(regex=(\"api\")).columns:\n",
    "        self[api_column] = self[api_column].apply(str)\\\n",
    "                                           .str.replace('\\W','')\\\n",
    "                                           .str.pad( 14\n",
    "                                                    ,side='right'\n",
    "                                                    ,fillchar='0'\n",
    "                                                   )\n",
    "    return self\n",
    "pd.DataFrame.parse_api_columns = parse_api_columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'clean_columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3715c74bcb10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m casing = pd.concat(map( pd.read_csv\n\u001b[0;32m----> 2\u001b[0;31m                        \u001b[0;34m,\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/welldatabase/casing/*.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m                       ))\\\n\u001b[1;32m      4\u001b[0m            \u001b[0;34m.\u001b[0m\u001b[0mclean_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m            \u001b[0;34m.\u001b[0m\u001b[0mparse_date_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/thom/.local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   4374\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4375\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4376\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4378\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'clean_columns'"
     ]
    }
   ],
   "source": [
    "casing = pd.concat(map( pd.read_csv\n",
    "                       ,glob.glob('./data/welldatabase/casing/*.csv')\n",
    "                      ))\\\n",
    "           .clean_column_names()\\\n",
    "           .parse_date_columns()\\\n",
    "           .parse_api_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = pd.concat(map( pd.read_csv\n",
    "                       ,glob.glob('./data/welldatabase/completion/*.csv')\n",
    "                      ))\\\n",
    "           .clean_column_names()\\\n",
    "           .parse_date_columns()\\\n",
    "           .parse_api_columns()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directional = pd.concat(map( pd.read_csv\n",
    "                       ,glob.glob('./data/welldatabase/directional/*.csv')\n",
    "                      ))\\\n",
    "           .clean_column_names()\\\n",
    "           .parse_date_columns()\\\n",
    "           .parse_api_columns()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formation = pd.concat(map( pd.read_csv\n",
    "                       ,glob.glob('./data/welldatabase/formation/*.csv')\n",
    "                      ))\\\n",
    "           .clean_column_names()\\\n",
    "           .parse_date_columns()\\\n",
    "           .parse_api_columns()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fracstage = pd.concat(map( pd.read_csv\n",
    "                       ,glob.glob('./data/welldatabase/fracstage/*.csv')\n",
    "                      ))\\\n",
    "           .clean_column_names()\\\n",
    "           .parse_date_columns()\\\n",
    "           .parse_api_columns()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = pd.concat(map( pd.read_csv\n",
    "                       ,glob.glob('./data/welldatabase/header/*.csv')\n",
    "                      ))\\\n",
    "           .clean_column_names()\\\n",
    "           .parse_date_columns()\\\n",
    "           .parse_api_columns()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf = pd.concat(map( pd.read_csv\n",
    "                       ,glob.glob('./data/welldatabase/perf/*.csv')\n",
    "                      ))\\\n",
    "           .clean_column_names()\\\n",
    "           .parse_date_columns()\\\n",
    "           .parse_api_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "production = pd.concat(map( pd.read_csv\n",
    "                       ,glob.glob('./data/welldatabase/production/*.csv')\n",
    "                      ))\\\n",
    "           .clean_column_names()\\\n",
    "           .parse_date_columns()\\\n",
    "           .parse_api_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "productionsummary = pd.concat(map( pd.read_csv\n",
    "                       ,glob.glob('./data/welldatabase/productionsummary/*.csv')\n",
    "                      ))\\\n",
    "           .clean_column_names()\\\n",
    "           .parse_date_columns()\\\n",
    "           .parse_api_columns()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.concat(map( pd.read_csv\n",
    "                       ,glob.glob('./data/welldatabase/test/*.csv')\n",
    "                      )\n",
    "                  )\\\n",
    "           .clean_column_names()\\\n",
    "           .parse_date_columns()\\\n",
    "           .parse_api_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_fraction(x):\n",
    "    try: \n",
    "        result = float(Fraction(x))\n",
    "    except AttributeError:\n",
    "        result = float(x)\n",
    "    except TypeError:\n",
    "        result = np.nan\n",
    "    except ValueError:\n",
    "        result = np.nan\n",
    "    while result > 1:\n",
    "        result = result / 64\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['chokesize_clean'] = test['chokesize'].str.replace('-','/')\\\n",
    "                                           .str.replace('TH','')\\\n",
    "                                           .str.strip('\"')\\\n",
    "                                           .str.strip(\"'\")\\\n",
    "                                           .str.replace(pat=\"OPEN|NONE|FO|OPEN FLOW\",repl='1')\\\n",
    "                                           .str.replace(pat=\"0|CLOSED|INSERT\",repl='')\\\n",
    "                                           .apply(string_to_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tubingandpacker = pd.concat(map( pd.read_csv\n",
    "                       ,glob.glob('./data/welldatabase/tubingandcasing/*.csv')\n",
    "                      ))\\\n",
    "           .clean_columns()\\\n",
    "           .parse_date_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = header[header['wellboreprofile']=='HORIZONTAL']\n",
    "sqdist = (header['surfacelatitude']-header['bottomholelatitude'])**2 + (header['surfacelongitude']-header['bottomholelongitude'])**2\n",
    "header['surface_to_bottomhole_distance'] = sqdist.map(lambda x: np.sqrt(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_reg = LinearRegression()\n",
    "xy=header.loc[header['surface_to_bottomhole_distance']!=0,['laterallength','surface_to_bottomhole_distance']].dropna()\n",
    "y = xy['laterallength'].values.reshape(-1, 1)\n",
    "X = xy['surface_to_bottomhole_distance'].values.reshape(-1, 1)\n",
    "linear_reg.fit(X=X,y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot( X ,y ,'o'\n",
    "         ,X,linear_reg.predict(X),'-k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header['laterallength_from_bottom'] = linear_reg.predict(header['surface_to_bottomhole_distance'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header['missing_laterallength'] =  header['laterallength'].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_summary = header.deduplicate('api',override={'missing_laterallength':'all'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = zero_to_null(completion,['upperperf','lowerperf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_summary = completion.deduplicate(['api','completiondate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_of_deepest_top = formation.groupby(\"api\").agg({'topdepth':'idxmax'})['topdepth'].dropna()\n",
    "formation_summary = formation.iloc[index_of_deepest_top].groupby('api').agg({'name':'first'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fracstage_summary = fracstage.deduplicate('api')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf = zero_to_null(perf,['lowerperf','upperperf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_summary = perf.deduplicate('api')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "production['yearmonth'] = production['date'].apply(lambda x: '{YEAR}-{MONTH:02d}'.format(YEAR=x.year,MONTH=x.month))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "production = production[production['yearmonth'] > '2011-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "production['days'] = pd.to_timedelta(production['days'],unit='D')\n",
    "production['first_producing_day_of_month'] = production['date'] + pd.DateOffset(months=1) - production['days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "production_summary = production.deduplicate(['api','yearmonth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_summary = test.deduplicate(['api','testdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "productionsummary_summary = productionsummary.deduplicate('api')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = header_summary.join(productionsummary_summary)\\\n",
    "                         .join(perf_summary)\\\n",
    "                         .join(fracstage_summary)\\\n",
    "                         .merge_multi(test_summary,on='api')\\\n",
    "                         .merge_multi(completion_summary,on='api')\\\n",
    "                         .merge_multi(production_summary,on='api')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['days_since_completion'] = ( combined['first_producing_day_of_month'] - combined['completiondate'] ) / np.timedelta64(1, 'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['increment_30days'] = combined['days_since_completion'].apply(lambda x: np.floor(x / 30) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = combined[combined['first_producing_day_of_month'] >= combined['completiondate']]\n",
    "combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_subset = combined[combined['increment_30days'].map(lambda x: 0 <= x <= 12)]\n",
    "combined_subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_subset = combined_subset.deduplicate(key=['api','increment_30days'],override={'oil':'sum'})\n",
    "combined_subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_subset['increment_30days'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_subset.to_csv('./data/welldb_combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
