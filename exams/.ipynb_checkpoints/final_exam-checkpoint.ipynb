{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STAT 5310 Test #3 Due December 12, 2018 at 5:30pm\n",
    "### Tom Wilson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Predict the number of applications received using the other variables in the college data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(data.table)\n",
    "library(glmnet)\n",
    "library(glmnetUtils)\n",
    "library(MASS)\n",
    "library(caret)\n",
    "library(leaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "college <- fread('../data/College.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a.\n",
    "Split the data set into a training set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "college <- college %>% subset(,-V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=nrow(college)\n",
    "train_sample <- runif(n,0,1) > 1 - 0.75 #random uniform sample\n",
    "college_train <- college[train_sample,] %>% select_if(is.numeric)\n",
    "college_test  <- college[!train_sample,] %>% select_if(is.numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train <- college_train %>% subset(,-Apps) \n",
    "y_train <- college_train %>% subset(, Apps) \n",
    "x_test  <- college_test  %>% subset(,-Apps) \n",
    "y_test  <- college_test  %>% subset(, Apps) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.\n",
    "Fit a linear model using least squares on the training set, and report the test error obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model <- lm(data = college_train, formula = Apps~.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=white-space:pre-wrap>'Root Mean Squared Error on test dataset =  12854.7300032995'</span>"
      ],
      "text/latex": [
       "'Root Mean Squared Error on test dataset =  12854.7300032995'"
      ],
      "text/markdown": [
       "<span style=white-space:pre-wrap>'Root Mean Squared Error on test dataset =  12854.7300032995'</span>"
      ],
      "text/plain": [
       "[1] \"Root Mean Squared Error on test dataset =  12854.7300032995\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "residual <- predict(linear_model,newdata = college_test) - college_test$Apps\n",
    "RMSE <- sqrt(sum(residual^2))\n",
    "paste('Root Mean Squared Error on test dataset = ',RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c.\n",
    "Fit a ridge regression model on the training set, with λ chosen by cross-validation.  Report the test error obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "k <- 10\n",
    "folds <- sample(1:k,nrow(college_train),replace <- TRUE)\n",
    "cv.errors <- setNames(data.frame(matrix(ncol = 3, nrow = 0)), c(\"fold\", \"lambda\", \"mae\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in data.table::data.table(...): Item 2 has no length. Provide at least one item (such as NA, NA_integer_ etc) to be repeated to match the 1 row in the longest column. Or, all columns can be 0 length, for insert()ing rows into.\n",
     "output_type": "error",
     "traceback": [
      "Error in data.table::data.table(...): Item 2 has no length. Provide at least one item (such as NA, NA_integer_ etc) to be repeated to match the 1 row in the longest column. Or, all columns can be 0 length, for insert()ing rows into.\nTraceback:\n",
      "1. as.vector(as.matrix(cbind(const = 1, x_train[folds == j])) %*% \n .     coef(fit))",
      "2. as.matrix(cbind(const = 1, x_train[folds == j]))",
      "3. cbind(const = 1, x_train[folds == j])",
      "4. cbind(deparse.level, ...)",
      "5. data.table::data.table(...)",
      "6. stop(\"Item \", i, \" has no length. Provide at least one item (such as NA, NA_integer_ etc) to be repeated to match the \", \n .     nr, \" row\", if (nr > 1L) \"s\", \" in the longest column. Or, all columns can be 0 length, for insert()ing rows into.\")"
     ]
    }
   ],
   "source": [
    "for(j in 1:k-1){\n",
    "    for(lambda in seq(0,1,0.1)) {    \n",
    "        fit <- lm.ridge(formula = Apps~.,data=college_train[folds!=j,], lambda=lambda)\n",
    "        pred <- as.vector(as.matrix(cbind(const=1,x_train[folds==j])) %*% coef(fit))\n",
    "        rmse <- sqrt( sum( ( y_train[folds==j] - pred)^2 ))\n",
    "        cv.errors <- rbind(cv.errors,c(j,lambda,rmse))\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames(cv.errors) <- c(\"fold\", \"lambda\", \"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_of_error <- cv.errors %>% group_by(lambda) %>% summarise(mean_rmse = mean(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in min(x):\n",
      "“no non-missing arguments to min; returning Inf”Warning message in max(x):\n",
      "“no non-missing arguments to max; returning -Inf”Warning message in min(x):\n",
      "“no non-missing arguments to min; returning Inf”Warning message in max(x):\n",
      "“no non-missing arguments to max; returning -Inf”"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in plot.window(...): need finite 'xlim' values\n",
     "output_type": "error",
     "traceback": [
      "Error in plot.window(...): need finite 'xlim' values\nTraceback:\n",
      "1. plot(x = summary_of_error$lambda, y = summary_of_error$mean_rmse)",
      "2. plot.default(x = summary_of_error$lambda, y = summary_of_error$mean_rmse)",
      "3. localWindow(xlim, ylim, log, asp, ...)",
      "4. plot.window(...)"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAA1BMVEX///+nxBvIAAAACXBI\nWXMAABJ0AAASdAHeZh94AAACw0lEQVR4nO3BgQAAAADDoPlTH+ECVQEAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMA3yB4AAXYzOhIAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(x = summary_of_error$lambda,y=summary_of_error$mean_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Root mean squared error steadily improves with larger values of lambda. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. \n",
    "Consider the Boston housing data set, from the MASS library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>crim</th><th scope=col>zn</th><th scope=col>indus</th><th scope=col>chas</th><th scope=col>nox</th><th scope=col>rm</th><th scope=col>age</th><th scope=col>dis</th><th scope=col>rad</th><th scope=col>tax</th><th scope=col>ptratio</th><th scope=col>black</th><th scope=col>lstat</th><th scope=col>medv</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.00632</td><td>18     </td><td>2.31   </td><td>0      </td><td>0.538  </td><td>6.575  </td><td>65.2   </td><td>4.0900 </td><td>1      </td><td>296    </td><td>15.3   </td><td>396.90 </td><td>4.98   </td><td>24.0   </td></tr>\n",
       "\t<tr><td>0.02731</td><td> 0     </td><td>7.07   </td><td>0      </td><td>0.469  </td><td>6.421  </td><td>78.9   </td><td>4.9671 </td><td>2      </td><td>242    </td><td>17.8   </td><td>396.90 </td><td>9.14   </td><td>21.6   </td></tr>\n",
       "\t<tr><td>0.02729</td><td> 0     </td><td>7.07   </td><td>0      </td><td>0.469  </td><td>7.185  </td><td>61.1   </td><td>4.9671 </td><td>2      </td><td>242    </td><td>17.8   </td><td>392.83 </td><td>4.03   </td><td>34.7   </td></tr>\n",
       "\t<tr><td>0.03237</td><td> 0     </td><td>2.18   </td><td>0      </td><td>0.458  </td><td>6.998  </td><td>45.8   </td><td>6.0622 </td><td>3      </td><td>222    </td><td>18.7   </td><td>394.63 </td><td>2.94   </td><td>33.4   </td></tr>\n",
       "\t<tr><td>0.06905</td><td> 0     </td><td>2.18   </td><td>0      </td><td>0.458  </td><td>7.147  </td><td>54.2   </td><td>6.0622 </td><td>3      </td><td>222    </td><td>18.7   </td><td>396.90 </td><td>5.33   </td><td>36.2   </td></tr>\n",
       "\t<tr><td>0.02985</td><td> 0     </td><td>2.18   </td><td>0      </td><td>0.458  </td><td>6.430  </td><td>58.7   </td><td>6.0622 </td><td>3      </td><td>222    </td><td>18.7   </td><td>394.12 </td><td>5.21   </td><td>28.7   </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllllllll}\n",
       " crim & zn & indus & chas & nox & rm & age & dis & rad & tax & ptratio & black & lstat & medv\\\\\n",
       "\\hline\n",
       "\t 0.00632 & 18      & 2.31    & 0       & 0.538   & 6.575   & 65.2    & 4.0900  & 1       & 296     & 15.3    & 396.90  & 4.98    & 24.0   \\\\\n",
       "\t 0.02731 &  0      & 7.07    & 0       & 0.469   & 6.421   & 78.9    & 4.9671  & 2       & 242     & 17.8    & 396.90  & 9.14    & 21.6   \\\\\n",
       "\t 0.02729 &  0      & 7.07    & 0       & 0.469   & 7.185   & 61.1    & 4.9671  & 2       & 242     & 17.8    & 392.83  & 4.03    & 34.7   \\\\\n",
       "\t 0.03237 &  0      & 2.18    & 0       & 0.458   & 6.998   & 45.8    & 6.0622  & 3       & 222     & 18.7    & 394.63  & 2.94    & 33.4   \\\\\n",
       "\t 0.06905 &  0      & 2.18    & 0       & 0.458   & 7.147   & 54.2    & 6.0622  & 3       & 222     & 18.7    & 396.90  & 5.33    & 36.2   \\\\\n",
       "\t 0.02985 &  0      & 2.18    & 0       & 0.458   & 6.430   & 58.7    & 6.0622  & 3       & 222     & 18.7    & 394.12  & 5.21    & 28.7   \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "crim | zn | indus | chas | nox | rm | age | dis | rad | tax | ptratio | black | lstat | medv | \n",
       "|---|---|---|---|---|---|\n",
       "| 0.00632 | 18      | 2.31    | 0       | 0.538   | 6.575   | 65.2    | 4.0900  | 1       | 296     | 15.3    | 396.90  | 4.98    | 24.0    | \n",
       "| 0.02731 |  0      | 7.07    | 0       | 0.469   | 6.421   | 78.9    | 4.9671  | 2       | 242     | 17.8    | 396.90  | 9.14    | 21.6    | \n",
       "| 0.02729 |  0      | 7.07    | 0       | 0.469   | 7.185   | 61.1    | 4.9671  | 2       | 242     | 17.8    | 392.83  | 4.03    | 34.7    | \n",
       "| 0.03237 |  0      | 2.18    | 0       | 0.458   | 6.998   | 45.8    | 6.0622  | 3       | 222     | 18.7    | 394.63  | 2.94    | 33.4    | \n",
       "| 0.06905 |  0      | 2.18    | 0       | 0.458   | 7.147   | 54.2    | 6.0622  | 3       | 222     | 18.7    | 396.90  | 5.33    | 36.2    | \n",
       "| 0.02985 |  0      | 2.18    | 0       | 0.458   | 6.430   | 58.7    | 6.0622  | 3       | 222     | 18.7    | 394.12  | 5.21    | 28.7    | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  crim    zn indus chas nox   rm    age  dis    rad tax ptratio black  lstat\n",
       "1 0.00632 18 2.31  0    0.538 6.575 65.2 4.0900 1   296 15.3    396.90 4.98 \n",
       "2 0.02731  0 7.07  0    0.469 6.421 78.9 4.9671 2   242 17.8    396.90 9.14 \n",
       "3 0.02729  0 7.07  0    0.469 7.185 61.1 4.9671 2   242 17.8    392.83 4.03 \n",
       "4 0.03237  0 2.18  0    0.458 6.998 45.8 6.0622 3   222 18.7    394.63 2.94 \n",
       "5 0.06905  0 2.18  0    0.458 7.147 54.2 6.0622 3   222 18.7    396.90 5.33 \n",
       "6 0.02985  0 2.18  0    0.458 6.430 58.7 6.0622 3   222 18.7    394.12 5.21 \n",
       "  medv\n",
       "1 24.0\n",
       "2 21.6\n",
       "3 34.7\n",
       "4 33.4\n",
       "5 36.2\n",
       "6 28.7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Boston %>% head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a.\n",
    "Based on this data set, provide an estimate for the population mean of medv.  Call this estimate  ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=white-space:pre-wrap>'an estimate for the population mean of medv is  22.5328063241107'</span>"
      ],
      "text/latex": [
       "'an estimate for the population mean of medv is  22.5328063241107'"
      ],
      "text/markdown": [
       "<span style=white-space:pre-wrap>'an estimate for the population mean of medv is  22.5328063241107'</span>"
      ],
      "text/plain": [
       "[1] \"an estimate for the population mean of medv is  22.5328063241107\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "estimate <- mean(Boston$medv)\n",
    "paste(\"an estimate for the population mean of medv is \",estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.\n",
    "Provide an estimate of the standard error of   Interpret this result.\n",
    "Hint:  We can compute the standard error of the sample mean by dividing the sample standard deviation by the square root of the number of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'an estimate of the standard error of the population mean of medv is 0.408861147497535'"
      ],
      "text/latex": [
       "'an estimate of the standard error of the population mean of medv is 0.408861147497535'"
      ],
      "text/markdown": [
       "'an estimate of the standard error of the population mean of medv is 0.408861147497535'"
      ],
      "text/plain": [
       "[1] \"an estimate of the standard error of the population mean of medv is 0.408861147497535\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n <- nrow(Boston)\n",
    "SE <- sd(Boston$medv)/sqrt(n)\n",
    "paste(\"an estimate of the standard error of the population mean of medv is\",SE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c.\n",
    "Now estimate the standard error of  using the bootstrap.  How does this compare to your answer from (b)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in alpha.fn(Portfolio, 1:100): object 'Portfolio' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in alpha.fn(Portfolio, 1:100): object 'Portfolio' not found\nTraceback:\n",
      "1. alpha.fn(Portfolio, 1:100)"
     ]
    }
   ],
   "source": [
    "alpha.fn=function(data,index){\n",
    " X=data$X[index]\n",
    " Y=data$Y[index]\n",
    " return((var(Y)-cov(X,Y))/(var(X)+var(Y)-2*cov(X,Y)))\n",
    " }\n",
    "alpha.fn(Portfolio,1:100)\n",
    "set.seed(1)\n",
    "alpha.fn(Portfolio,sample(100,100,replace=T))\n",
    "boot(Portfolio,alpha.fn,R=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d.\n",
    "Based on your bootstrap estimate from (c), provide a 95% confidence interval for the mean of medv. compare it to the results obtained using t.test(Boston$medv).\n",
    "\n",
    "Hint:  You can approximate a 95% confidence interval using the formula "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chapter 6 Lab 1: Subset Selection Methods\n",
    "#Install package ISLR and leaps\n",
    "# Best Subset Selection\n",
    "library(ISLR)\n",
    "fix(Hitters)\n",
    "names(Hitters)\n",
    "dim(Hitters)\n",
    "sum(is.na(Hitters$Salary))\n",
    "Hitters=na.omit(Hitters)\n",
    "dim(Hitters)\n",
    "#reduces the rows from 322 to 263\n",
    "sum(is.na(Hitters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(leaps)\n",
    "#regsubests from leaps provides a model search for the best subsets of each size up to nvmax exhaustive\n",
    "#is the default method\n",
    "\n",
    "regfit.full=regsubsets(Salary~.,Hitters)\n",
    "summary(regfit.full)\n",
    "regfit.full=regsubsets(Salary~.,data=Hitters,nvmax=19)\n",
    "reg.summary=summary(regfit.full)\n",
    "names(reg.summary)\n",
    "\n",
    "reg.summary$rsq\n",
    "\n",
    "par(mfrow=c(2,2))\n",
    "plot(reg.summary$rss,xlab=\"Number of Variables\",ylab=\"RSS\",type=\"l\")\n",
    "plot(reg.summary$adjr2,xlab=\"Number of Variables\",ylab=\"Adjusted RSq\",type=\"l\")\n",
    "which.max(reg.summary$adjr2)\n",
    "#which.max returns 11 which we then include in the previous plot for ajr2\n",
    "points(11,reg.summary$adjr2[11], col=\"red\",cex=2,pch=20)\n",
    "\n",
    "plot(reg.summary$cp,xlab=\"Number of Variables\",ylab=\"Cp\",type='l')\n",
    "which.min(reg.summary$cp)\n",
    "#returns 10 which we then include in the previous Cp plot\n",
    "points(10,reg.summary$cp[10],col=\"red\",cex=2,pch=20)\n",
    "\n",
    "which.min(reg.summary$bic)\n",
    "#returns 6\n",
    "plot(reg.summary$bic,xlab=\"Number of Variables\",ylab=\"BIC\",type='l')\n",
    "points(6,reg.summary$bic[6],col=\"red\",cex=2,pch=20)\n",
    "\n",
    "\n",
    "plot(regfit.full,scale=\"r2\")\n",
    "plot(regfit.full,scale=\"adjr2\")\n",
    "plot(regfit.full,scale=\"Cp\")\n",
    "plot(regfit.full,scale=\"bic\")\n",
    "#Returns the coefficients from the model search of variables\n",
    "coef(regfit.full,6)\n",
    "\n",
    "# Forward and Backward Stepwise Selection\n",
    "\n",
    "regfit.fwd=regsubsets(Salary~.,data=Hitters,nvmax=19,method=\"forward\")\n",
    "summary(regfit.fwd)\n",
    "regfit.bwd=regsubsets(Salary~.,data=Hitters,nvmax=19,method=\"backward\")\n",
    "summary(regfit.bwd)\n",
    "#Exhaustive comes up with a slightly different 7 variable model than Forward and Backward\n",
    "coef(regfit.full,7)\n",
    "coef(regfit.fwd,7)\n",
    "coef(regfit.bwd,7)\n",
    "\n",
    "# Choosing Among Models\n",
    "\n",
    "set.seed(1)\n",
    "#Creates a vector of True and Falses with length equal to the rows of Hitters\n",
    "train=sample(c(TRUE,FALSE), nrow(Hitters),rep=TRUE)\n",
    "test=(!train)\n",
    "\n",
    "#Find the best subsets using only the True rows from train\n",
    "regfit.best=regsubsets(Salary~.,data=Hitters[train,],nvmax=19)\n",
    "\n",
    "test.mat=model.matrix(Salary~.,data=Hitters[test,])\n",
    "\n",
    "#To calculate the validation error for each model\n",
    "val.errors=rep(NA,19)\n",
    "for(i in 1:19){\n",
    "   coefi=coef(regfit.best,id=i)\n",
    "   pred=test.mat[,names(coefi)]%*%coefi\n",
    "   val.errors[i]=mean((Hitters$Salary[test]-pred)^2)\n",
    "}\n",
    "val.errors\n",
    "\n",
    "which.min(val.errors)\n",
    "#Returns 10\n",
    "\n",
    "coef(regfit.best,10)\n",
    "\n",
    "\n",
    "predict.regsubsets=function(object,newdata,id,...){\n",
    "  form=as.formula(object$call[[2]])\n",
    "  mat=model.matrix(form,newdata)\n",
    "  coefi=coef(object,id=id)\n",
    "  xvars=names(coefi)\n",
    "  mat[,xvars]%*%coefi\n",
    "  }\n",
    "\n",
    "#Slightly different variables selected when using the full data set as compared to the training\n",
    "regfit.best=regsubsets(Salary~.,data=Hitters,nvmax=19)\n",
    "coef(regfit.best,10)\n",
    "\n",
    "#10-fold Cross-validation\n",
    "k=10\n",
    "set.seed(1)\n",
    "folds=sample(1:k,nrow(Hitters),replace=TRUE)\n",
    "cv.errors=matrix(NA,k,19, dimnames=list(NULL, paste(1:19)))\n",
    "for(j in 1:k){\n",
    "  best.fit=regsubsets(Salary~.,data=Hitters[folds!=j,],nvmax=19)\n",
    "  for(i in 1:19){\n",
    "    pred=predict(best.fit,Hitters[folds==j,],id=i)\n",
    "    cv.errors[j,i]=mean( (Hitters$Salary[folds==j]-pred)^2)\n",
    "    }\n",
    "  }\n",
    "mean.cv.errors=apply(cv.errors,2,mean)\n",
    "mean.cv.errors\n",
    "\n",
    "par(mfrow=c(1,1))\n",
    "plot(mean.cv.errors,type='b')\n",
    "#11 seems to have the smallest error\n",
    "\n",
    "reg.best=regsubsets(Salary~.,data=Hitters, nvmax=19)\n",
    "coef(reg.best,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ridge Regression and the Lasso\n",
    "\n",
    "x=model.matrix(Salary~.,Hitters)[,-1]\n",
    "#[,-1] excludes the first column in the list of predictos\n",
    "y=Hitters$Salary\n",
    "\n",
    "# Ridge Regression\n",
    "\n",
    "library(glmnet)\n",
    "grid=10^seq(10,-2,length=100)\n",
    "ridge.mod=glmnet(x,y,alpha=0,lambda=grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim(coef(ridge.mod))\n",
    "ridge.mod$lambda[50]\n",
    "coef(ridge.mod)[,50]\n",
    "sqrt(sum(coef(ridge.mod)[-1,50]^2))\n",
    "ridge.mod$lambda[60]\n",
    "coef(ridge.mod)[,60]\n",
    "sqrt(sum(coef(ridge.mod)[-1,60]^2))\n",
    "predict(ridge.mod,s=50,type=\"coefficients\")[1:20,]\n",
    "set.seed(1)\n",
    "train=sample(1:nrow(x), nrow(x)/2)\n",
    "test=(-train)\n",
    "y.test=y[test]\n",
    "ridge.mod=glmnet(x[train,],y[train],alpha=0,lambda=grid, thresh=1e-12)\n",
    "ridge.pred=predict(ridge.mod,s=4,newx=x[test,])\n",
    "mean((ridge.pred-y.test)^2)\n",
    "mean((mean(y[train])-y.test)^2)\n",
    "ridge.pred=predict(ridge.mod,s=1e10,newx=x[test,])\n",
    "mean((ridge.pred-y.test)^2)\n",
    "ridge.pred=predict(ridge.mod,s=0,newx=x[test,],exact=T)\n",
    "mean((ridge.pred-y.test)^2)\n",
    "lm(y~x, subset=train)\n",
    "predict(ridge.mod,s=0,exact=T,type=\"coefficients\")[1:20,]\n",
    "set.seed(1)\n",
    "cv.out=cv.glmnet(x[train,],y[train],alpha=0)\n",
    "plot(cv.out)\n",
    "bestlam=cv.out$lambda.min\n",
    "bestlam\n",
    "ridge.pred=predict(ridge.mod,s=bestlam,newx=x[test,])\n",
    "mean((ridge.pred-y.test)^2)\n",
    "out=glmnet(x,y,alpha=0)\n",
    "predict(out,type=\"coefficients\",s=bestlam)[1:20,]\n",
    "\n",
    "# The Lasso\n",
    "\n",
    "lasso.mod=glmnet(x[train,],y[train],alpha=1,lambda=grid)\n",
    "plot(lasso.mod)\n",
    "set.seed(1)\n",
    "cv.out=cv.glmnet(x[train,],y[train],alpha=1)\n",
    "plot(cv.out)\n",
    "bestlam=cv.out$lambda.min\n",
    "lasso.pred=predict(lasso.mod,s=bestlam,newx=x[test,])\n",
    "mean((lasso.pred-y.test)^2)\n",
    "out=glmnet(x,y,alpha=1,lambda=grid)\n",
    "lasso.coef=predict(out,type=\"coefficients\",s=bestlam)[1:20,]\n",
    "lasso.coef\n",
    "lasso.coef[lasso.coef!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Validation Set Approach\n",
    "\n",
    "\n",
    "Auto=read.csv(\"H:/STAT 5310/Auto.csv\",header=T,na.strings=\"?\")\n",
    "Auto=na.omit(Auto)\n",
    "dim(Auto)\n",
    "names(Auto)\n",
    "\n",
    "library(ISLR)\n",
    "set.seed(1)\n",
    "train=sample(392,196)\n",
    "lm.fit=lm(mpg~horsepower,data=Auto,subset=train)\n",
    "attach(Auto)\n",
    "mean((mpg-predict(lm.fit,Auto))[-train]^2)\n",
    "#26.14142\n",
    "\n",
    "lm.fit2=lm(mpg~poly(horsepower,2),data=Auto,subset=train)\n",
    "mean((mpg-predict(lm.fit2,Auto))[-train]^2)\n",
    "#19.82259\n",
    "\n",
    "lm.fit3=lm(mpg~poly(horsepower,3),data=Auto,subset=train)\n",
    "mean((mpg-predict(lm.fit3,Auto))[-train]^2)\n",
    "#19.78252\n",
    "\n",
    "set.seed(2)\n",
    "train=sample(392,196)\n",
    "lm.fit=lm(mpg~horsepower,subset=train)\n",
    "mean((mpg-predict(lm.fit,Auto))[-train]^2)\n",
    "#23.29559\n",
    "\n",
    "lm.fit2=lm(mpg~poly(horsepower,2),data=Auto,subset=train)\n",
    "mean((mpg-predict(lm.fit2,Auto))[-train]^2)\n",
    "#18.90124\n",
    "\n",
    "lm.fit3=lm(mpg~poly(horsepower,3),data=Auto,subset=train)\n",
    "mean((mpg-predict(lm.fit3,Auto))[-train]^2)\n",
    "#19.2574\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Leave-One-Out Cross-Validation\n",
    "\n",
    "glm.fit=glm(mpg~horsepower,data=Auto)\n",
    "coef(glm.fit)\n",
    "lm.fit=lm(mpg~horsepower,data=Auto)\n",
    "coef(lm.fit)\n",
    "\n",
    "library(boot)\n",
    "glm.fit=glm(mpg~horsepower,data=Auto)\n",
    "\n",
    "#cv.glm k-fold cross-validationn prediction error default is k=n \n",
    "cv.err=cv.glm(Auto,glm.fit)\n",
    "cv.err$delta\n",
    "cv.error=rep(0,5)\n",
    "for (i in 1:5){\n",
    " glm.fit=glm(mpg~poly(horsepower,i),data=Auto)\n",
    " cv.error[i]=cv.glm(Auto,glm.fit)$delta[1]\n",
    " }\n",
    "cv.error\n",
    "#24.23151 19.24821 19.33498 19.42443 19.03321\n",
    "\n",
    "# k-Fold Cross-Validation\n",
    "\n",
    "#cv.glm k=10 10-fold cross validation \n",
    "set.seed(17)\n",
    "cv.error.10=rep(0,10)\n",
    "for (i in 1:10){\n",
    " glm.fit=glm(mpg~poly(horsepower,i),data=Auto)\n",
    " cv.error.10[i]=cv.glm(Auto,glm.fit,K=10)$delta[1]\n",
    " }\n",
    "cv.error.10\n",
    "\n",
    "# The Bootstrap example from PowerPoint\n",
    "\n",
    "alpha.fn=function(data,index){\n",
    " X=data$X[index]\n",
    " Y=data$Y[index]\n",
    " return((var(Y)-cov(X,Y))/(var(X)+var(Y)-2*cov(X,Y)))\n",
    " }\n",
    "alpha.fn(Portfolio,1:100)\n",
    "set.seed(1)\n",
    "alpha.fn(Portfolio,sample(100,100,replace=T))\n",
    "boot(Portfolio,alpha.fn,R=1000)\n",
    "\n",
    "# Estimating the Accuracy of a Linear Regression Model\n",
    "\n",
    "boot.fn=function(data,index)\n",
    " return(coef(lm(mpg~horsepower,data=data,subset=index)))\n",
    "\n",
    "boot.fn(Auto,1:392)\n",
    "set.seed(1)\n",
    "boot.fn(Auto,sample(392,392,replace=T))\n",
    "boot.fn(Auto,sample(392,392,replace=T))\n",
    "#Different results due to different with replacement samples\n",
    "\n",
    "boot(Auto,boot.fn,1000)\n",
    "summary(lm(mpg~horsepower,data=Auto))$coef\n",
    "#See how similar the results are bootstrap estimates vs. full sample\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
