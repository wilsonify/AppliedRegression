---
title: "Oilwell Completion Regression - Literature Review"
author: "Thomas Wilson"
date: "September 9, 2018"
output: pdf_document
bibliography: references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<!-- 
*Total length of literature review should be about 4 single-spaced pages or more (not counting the references page.)*

*Documented in APA style, with section headings for major sections as well as subtopics*
-->

# Introduction

For centuries, oilwells have been drilled vertically and completed by perforation only. Since the invention of horizontal drilling, literature as shown clearly that various completion parameters have a significant effect on oil production. 

# Body
Using relevant headings, the body should be composed of sections. 
They take up each issue one at a time and discuss how the authors of the articles respond to that issue. 

Don’t forget to introduce and close each section with a sentence focused on the literature (topic sentence and concluding sentence.)

Length of body: about 3 pages or more, single-spaced. (Length of each section will vary, but each typically contains several paragraphs.)
 
 
 



The implementation of geo-engineered designs as described in this paper have shown field success and
represents another achievement in completion design workflows for single well applications. Advances in
horizontal completion design are rapidly evolving. Recent advances in horizontal completion designs have
demonstrated the following:
1.
2.
3.
4.
Mega-frac jobs with high proppant loading and large fluid volumes work in nearly every basin.
Geo-engineered completions and degradable diversion improve cluster efficiency.
A proven 3D earth model is essential in determining lateral landing sweet spots accurately.
Big data has value. The current trend towards statistical modeling and machine learning are helping
to determine a reservoir's unique DNA attributes which lead to optimizing production.
5. Determining the factors/attributes driving production requires large amounts of data from multiple
wells as input to perform multivariate analysis for each potential interval.
6. In the absence of large amounts of data (e.g., exploration settings) the combination of high proppant
loading, geo-engineered design and the use of degradable diversion are logical steps in establishing
baseline performance to approximate best in class production within a given area.[@fulks2016optimizing]


In conclusion we have demonstrated how efficiently, intuitively and easily data-driven insights can be
achieved in not just the planning and design phases of an operation, but also in how these models can be
rapidly implemented as prescriptive solutions utilized in the operational phase. The analytical workflows,
models and exploratory data analysis carried out in this study are cornerstones to other data-driven
methodologies you could implement to address a diverse array of business problems in the upstream.
When marrying data-driven analytics with first principles we can establish a robust and repeatable suite
of workflows to convert raw data into actionable knowledge. This paper illustrates one such example
study.[@holdaway2015drilling]

As far as the relative importance of variables is concerned; fracture half-length is very significant where fracture bottom has more significance than that of fracture top in this specific case. Total proppant used has similar significance as fracture height. Pay zone coverage, slurry volume, and average fracture conductivity have similar amounts of significance. The cause-effect (input-output) relationship is shown above for each parameter in Figs. 8 through 16. 
  Data analytics tools have been utilized to analyze the results of a fracture model built with a commercial fracture simulator. Utilization of the fracture simulator with enabled us to investigate the significance of each parameter on the outcome that was used as an input to the data analytics software to analyze the input-output relationship to  capture not only the significance of the inputs but also theSPE-177549-MS 25 direction that the inputs affect the outcome by means of fitting a neural model to the data and displaying it in 3D surface profiler as well as the 2D profiler which were illustrated in figures 8–16. It would not be possible without the use of data analytics tool to clearly show the direction of impact of each input. The conclusions pertain to this specific model, as neural model that was fit is a data driven model and highly belongs to the model used. However, it serves as a use[@temizel2015efficient]
 

1. The PCD and IOD visual analysis methodology is suitable for testing any input's impact on production
performance with careful consideration of dimensionally normalizing both performance measures and
inputs. Multiple performance measures should be used to maximize the number of patterns identified.
2. Given that demonstrable patterns were identifiable in all study areas, this methodology appears to be
suitable for all types of plays where inputs have enough statistical variability to see measurable results.12
SPE-185077-MS
3. This approach is effective at communicating nuances in the data, such as thresholds and correlation
windows that are not easily identified using other techniques. Further, specific threshold values and
correlation window ranges can be valuable inputs to other regression techniques or modelling efforts.
4. The approach is scalable, accommodating datasets containing greater than 1000 wells down to as few
as 80 wells.
5. Inexplicable patterns are an effective way of identifying the need for analogue review and subset
selection. It is essential that analogue subsets be explored to refine insights before drawing discernable
conclusions.[@groulx2017multivariate]


Proxy modeling is not a new concept and had been in the industry for many years. However, the workflow
and approach described in this study are unique in creating "synthetic" big data out of simulations based
on fundamental science honoring rock physics, fluid flow, hydraulic fracture propagation in complex14
SPE-189790-MS
environments, and numerical reservoir simulation. Using parametric explosion of sensitivity parameters, the
synthetic big data use for creating a proxy model to predict hydraulic fracture performance in unconventional
reservoirs has been demonstrated successfully.
This proxy model allows engineers to design the completions and predict the response to production and
NPV almost real-time for the wells to be drilled and completed in the proximity of the base model. As long
as the geology does not significantly vary, the directional response for optimum well completion can be
derived from the proxy modeling much faster than full field/pad scale modeling and simulations converting
the decision making a matter of minutes instead of days and months.
The specific learnings and observations from application of the workflow on the base model from Eagle
Ford in this study are:
1. A calibrated model is a fundamental step to create a reliable predictive proxy.
2. The Predictive proxy models had an excellent predictability on all four targets of B1, B3, B12 and
Cum_5
3. Higher accuracy is achieved for long term predictions (Cum 5 > B1)
The predictive proxy has a wide variety of application amongst the domains of completion engineers and
management to undertake more informed decision making and completion optimization. Similar approach
in the fields of drilling, artificial lift, production and numerical simulation can be applied to speed the model-
to-decision cycle.[@pankaj2018need]


The rapid proliferation of sensing and data acquisition systems combined with cheap data storage is resulting in the age of
“Big Data” and the most scarce resource going forward is likely to be expert time to go through, clean and label the data. This
has led to the rising importance of adopting new strategies and workflows for the development of advanced analytics models.
This trend is already visible in other industries and is likely to be a big challenge for the oil and gas industry as well. In this
work, we explored the use of active learning to intelligently identify data points with the highest value of information and
semi-supervised learning to combine the information from labeled and unlabeled sources in an optimal fashion. It was
demonstrated that these advanced machine learning methods show considerable promise and can be integral tools in making
the entire analysis procedure more interactive and productive. Effective adoption of these advanced machine learning
techniques for interactive learning will be dependent on their integration with excellent data visualization and effective user
interface design.[@subrahmanya2014advanced]

A framework of big data analytics is developed to measure the efficacy factor of fracturing fluid ingredients
in terms their effectiveness on well productivity, based on FracFocus and well production databases. Such
efficacy factors could serve as justification for chemical product approvals and denials.
As a useful demonstration, chemical ingredients that are conducive to production of wells with Marcellus
shale geology are quantitatively differentiated those that negatively impact gas productivity. The specific
efficacy factors may not be directly applicable in other fields, but the framework of data analysis can be
easily applied.
The data analytics framework helps providing leads in understanding the intricate chemical and physical
processes of fracturing fluids. It points the direction to the causality - those kinds of cause-effect
relationships – between ingredient and productivity straight from real-world data.
Each well is a geophysical experiment. Compared with fracturing fluid lab test that still needs to be
optimized in the field, the data analytics framework learns hidden connections from field data, which is the
ultimate experiment, and reduces or stops the guesswork.[@zhang2018mining]



# Conclusion
<!-- 
Summarize what the literature says about your topic. 
Approximate length: about ¼ page.
-->